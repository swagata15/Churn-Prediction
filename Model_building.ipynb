{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Importing Libraries ####\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset = pd.read_csv('new_churn_data.csv')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier,\n",
    "                             X = X_train[X_train.columns[rfe.support_]],\n",
    "                             y = y_train, cv = 10)\n",
    "print(\"SVM Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))\n",
    "\n",
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(X_train[X_train.columns[rfe.support_]].columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n",
    "\n",
    "\n",
    "#### End of Model ####\n",
    "\n",
    "\n",
    "# Formatting Final Results\n",
    "final_results = pd.concat([y_test, user_identifier], axis = 1).dropna()\n",
    "final_results['predicted_churn'] = y_pred\n",
    "final_results = final_results[['user', 'churn', 'predicted_churn']].reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Preparation\n",
    "user_identifier = dataset['user']\n",
    "dataset = dataset.drop(columns = ['user'])\n",
    "\n",
    "# One-Hot Encoding\n",
    "dataset.housing.value_counts()\n",
    "dataset.groupby('housing')['churn'].nunique().reset_index()\n",
    "dataset = pd.get_dummies(dataset)\n",
    "dataset.columns\n",
    "dataset = dataset.drop(columns = ['housing_na', 'zodiac_sign_na', 'payment_type_na'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.drop(columns = 'churn'), dataset['churn'],\n",
    "                                                    test_size = 0.2,\n",
    "                                                    random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balancing the Training Set\n",
    "y_train.value_counts()\n",
    "\n",
    "pos_index = y_train[y_train.values == 1].index\n",
    "neg_index = y_train[y_train.values == 0].index\n",
    "\n",
    "if len(pos_index) > len(neg_index):\n",
    "    higher = pos_index\n",
    "    lower = neg_index\n",
    "else:\n",
    "    higher = neg_index\n",
    "    lower = pos_index\n",
    "\n",
    "random.seed(0)\n",
    "higher = np.random.choice(higher, size=len(lower))\n",
    "lower = np.asarray(lower)\n",
    "new_indexes = np.concatenate((lower, higher))\n",
    "\n",
    "X_train = X_train.loc[new_indexes,]\n",
    "y_train = y_train[new_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train2 = pd.DataFrame(sc_X.fit_transform(X_train))\n",
    "X_test2 = pd.DataFrame(sc_X.transform(X_test))\n",
    "X_train2.columns = X_train.columns.values\n",
    "X_test2.columns = X_test.columns.values\n",
    "X_train2.index = X_train.index.values\n",
    "X_test2.index = X_test.index.values\n",
    "X_train = X_train2\n",
    "X_test = X_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Building ####\n",
    "\n",
    "\n",
    "# Fitting Model to the Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluating Results\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)\n",
    "precision_score(y_test, y_pred) # tp / (tp + fp)\n",
    "recall_score(y_test, y_pred) # tp / (tp + fn)\n",
    "f1_score(y_test, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Applying k-Fold Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\n",
    "print(\"SVM Accuracy: %0.3f (+/- %0.3f)\" % (accuracies.mean(), accuracies.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing Coefficients\n",
    "pd.concat([pd.DataFrame(X_train.columns, columns = [\"features\"]),\n",
    "           pd.DataFrame(np.transpose(classifier.coef_), columns = [\"coef\"])\n",
    "           ],axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Feature Selection ####\n",
    "\n",
    "\n",
    "## Feature Selection\n",
    "# Recursive Feature Elimination\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Model to Test\n",
    "classifier = LogisticRegression()\n",
    "# Select Best X Features\n",
    "rfe = RFE(classifier, 20)\n",
    "rfe = rfe.fit(X_train, y_train)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "X_train.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Correlation Matrix\n",
    "sn.set(style=\"white\")\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = X_train[X_train.columns[rfe.support_]].corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(18, 15))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sn.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sn.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Model to the Training Set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train[X_train.columns[rfe.support_]], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting Test Set\n",
    "y_pred = classifier.predict(X_test[X_train.columns[rfe.support_]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating Results\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)\n",
    "precision_score(y_test, y_pred) # tp / (tp + fp)\n",
    "recall_score(y_test, y_pred) # tp / (tp + fn)\n",
    "f1_score(y_test, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = (1, 0), columns = (1, 0))\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4)\n",
    "sn.heatmap(df_cm, annot=True, fmt='g')\n",
    "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
